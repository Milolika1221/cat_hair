import tensorflow as tf
import numpy as np
import json
import os
import logging
from typing import Dict, Any, List, Tuple

logger = logging.getLogger(__name__)

class DualModelLoader:
    # –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π: —Ñ–∏–ª—å—Ç—Ä –∫–æ—Ç–∞ –∏ –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å —Å—Ç—Ä–∏–∂–µ–∫
    
    def __init__(self, 
                main_model_dir: str = "cat_server\infrastructure\models\main_model", 
                 cat_filter_model_dir: str = "cat_server\infrastructure\models\cat_filter"):  
        self.main_model_dir = main_model_dir
        self.cat_filter_model_dir = cat_filter_model_dir
        self.main_model = None
        self.cat_filter_model = None
        self.main_metadata = None
        self.cat_filter_metadata = None
        
    def load_models(self) -> bool:
        try:
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å-—Ñ–∏–ª—å—Ç—Ä –∫–æ—Ç–∞
            if not os.path.exists(os.path.join(self.cat_filter_model_dir, "saved_model.pb")):
                logger.error("‚ùå –ú–æ–¥–µ–ª—å-—Ñ–∏–ª—å—Ç—Ä –∫–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            self.cat_filter_model = tf.saved_model.load(self.cat_filter_model_dir)
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å-—Ñ–∏–ª—å—Ç—Ä –∫–æ—Ç–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å —Å—Ç—Ä–∏–∂–µ–∫
            if not os.path.exists(os.path.join(self.main_model_dir, "saved_model.pb")):
                logger.error("‚ùå –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å —Å—Ç—Ä–∏–∂–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            self.main_model = tf.saved_model.load(self.main_model_dir)
            logger.info("‚úÖ –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å —Å—Ç—Ä–∏–∂–µ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self._load_metadata()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            return False
    
    def _load_metadata(self):
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏-—Ñ–∏–ª—å—Ç—Ä–∞
        cat_metadata_path = os.path.join(self.cat_filter_model_dir, "metadata.json")
        if os.path.exists(cat_metadata_path):
            with open(cat_metadata_path, 'r', encoding='utf-8') as f:
                self.cat_filter_metadata = json.load(f)
            logger.info(f"üìä –ö–ª–∞—Å—Å—ã —Ñ–∏–ª—å—Ç—Ä–∞: {self.cat_filter_metadata.get('labels', [])}")
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
        main_metadata_path = os.path.join(self.main_model_dir, "metadata.json")
        if os.path.exists(main_metadata_path):
            with open(main_metadata_path, 'r', encoding='utf-8') as f:
                self.main_metadata = json.load(f)
            logger.info(f"üìä –ö–ª–∞—Å—Å—ã –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏: {self.main_metadata.get('labels', [])}")
    
    def preprocess_image(self, image_data: bytes) -> np.ndarray:
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        try:
            image = tf.image.decode_image(image_data, channels=3)
            image = tf.image.resize(image, [224, 224])
            image = tf.cast(image, tf.float32) / 255.0
            image = tf.expand_dims(image, axis=0)
            return image.numpy()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            raise
    
    def is_cat_image(self, image_data: bytes, confidence_threshold: float = 0.8) -> Tuple[bool, float]:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ—Ç–æ–º —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏-—Ñ–∏–ª—å—Ç—Ä–∞
        try:
            processed_image = self.preprocess_image(image_data)
            input_tensor = tf.constant(processed_image)

            predictions = self.cat_filter_model.signatures["serving_default"](input_tensor)
            output_key = list(predictions.keys())[0]
            scores = predictions[output_key].numpy()[0]
            
            filter_labels = self.cat_filter_metadata.get('labels', ['cat', 'not_cat'])
            
            cat_confidence = 0.0
            for i, label in enumerate(filter_labels):
                if i < len(scores):
                    if label.lower() == 'cat':
                        cat_confidence = float(scores[i])
                        break
            else:
                cat_confidence = float(scores[0])
            
            is_cat = cat_confidence >= confidence_threshold
            logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—Ç–∞: {is_cat} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {cat_confidence:.2f}, –ø–æ—Ä–æ–≥: {confidence_threshold})")
            
            return is_cat, cat_confidence
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ—Ç–∞: {e}")
            return False, 0.0
    
    def predict_hairstyle(self, image_data: bytes) -> Dict[str, Any]:
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç—Ä–∏–∂–∫–∏
        if self.main_model is None:
            if not self.load_models():
                raise Exception("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
        try:
            processed_image = self.preprocess_image(image_data)
            input_tensor = tf.constant(processed_image)
            
            predictions = self.main_model.signatures["serving_default"](input_tensor)
            output_key = list(predictions.keys())[0]
            scores = predictions[output_key].numpy()[0]
            
            labels = self.main_metadata.get('labels', [f'Class_{i}' for i in range(len(scores))])
            
            results = []
            for i, score in enumerate(scores):
                results.append({
                    "class_name": labels[i] if i < len(labels) else f"Class_{i}",
                    "confidence": float(score),
                    "percentage": f"{float(score) * 100:.2f}%"
                })
            
            results.sort(key=lambda x: x["confidence"], reverse=True)
            
            return {
                "success": True,
                "predictions": results,
                "top_prediction": results[0] if results else None
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∏–∂–∫–∏: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def predict(self, image_data: bytes, require_cat: bool = True) -> Dict[str, Any]:
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫–æ—Ç–∞
        if self.main_model is None or self.cat_filter_model is None:
            if not self.load_models():
                raise Exception("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ—Ç–æ–º
            if require_cat:
                is_cat, cat_confidence = self.is_cat_image(image_data)
                if not is_cat:
                    return {
                        "success": False,
                        "error": "not_a_cat",
                        "message": "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –∫–æ—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ –∫–æ—Ç–∞.",
                        "cat_confidence": cat_confidence,
                        "required_confidence": 0.8
                    }
            
            # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ—Ç –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞ - –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç—Ä–∏–∂–∫–∏
            hairstyle_result = self.predict_hairstyle(image_data)
            
            if hairstyle_result["success"]:
                hairstyle_result["is_cat"] = True if require_cat else None
                if require_cat:
                    hairstyle_result["cat_confidence"] = cat_confidence
            
            return hairstyle_result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {
                "success": False,
                "error": str(e)
            }