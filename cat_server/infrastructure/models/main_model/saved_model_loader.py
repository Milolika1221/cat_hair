import tensorflow as tf
import numpy as np
import json
import os
import logging
from typing import Dict, Any, List

logger = logging.getLogger(__name__)

class SavedModelLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è –º–æ–¥–µ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ SavedModel –∏–∑ Teachable Machine"""
    
    def __init__(self, model_dir: str = "infrastructure/models"):
        self.model_dir = model_dir
        self.model = None
        self.metadata = None
        
    def load_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ SavedModel"""
        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ SavedModel –∏–∑: {self.model_dir}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if not os.path.exists(os.path.join(self.model_dir, "saved_model.pb")):
                logger.error("‚ùå –§–∞–π–ª saved_model.pb –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = tf.saved_model.load(self.model_dir)
            logger.info("‚úÖ SavedModel –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            metadata_path = os.path.join(self.model_dir, "metadata.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                logger.info(f"üìä –ö–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–∏: {self.metadata.get('labels', [])}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ SavedModel: {e}")
            return False
    
    def preprocess_image(self, image_data: bytes) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏"""
        try:
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = tf.image.decode_image(image_data, channels=3)
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ 224x224 (—Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è Teachable Machine)
            image = tf.image.resize(image, [224, 224])
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º [0, 1]
            image = tf.cast(image, tf.float32) / 255.0
            
            # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
            image = tf.expand_dims(image, axis=0)
            
            return image.numpy()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            raise
    
    def predict(self, image_data: bytes) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        if self.model is None:
            if not self.load_model():
                raise Exception("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            processed_image = self.preprocess_image(image_data)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä TensorFlow
            input_tensor = tf.constant(processed_image)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            # –î–ª—è SavedModel –∏—Å–ø–æ–ª—å–∑—É–µ–º serving_default —Å–∏–≥–Ω–∞—Ç—É—Ä—É
            predictions = self.model.signatures["serving_default"](input_tensor)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
            output_key = list(predictions.keys())[0]
            scores = predictions[output_key].numpy()[0]
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            labels = self.metadata.get('labels', [f'Class_{i}' for i in range(len(scores))])
            
            results = []
            for i, score in enumerate(scores):
                results.append({
                    "class_name": labels[i] if i < len(labels) else f"Class_{i}",
                    "confidence": float(score),
                    "percentage": f"{float(score) * 100:.2f}%"
                })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            results.sort(key=lambda x: x["confidence"], reverse=True)
            
            return {
                "success": True,
                "predictions": results,
                "top_prediction": results[0] if results else None
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {
                "success": False,
                "error": str(e)
            }