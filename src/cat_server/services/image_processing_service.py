# services/image_processing_service.py

import asyncio
import base64
import io
import json
import logging
from datetime import datetime
from typing import Any, Dict, List

import aiohttp
from PIL import Image as PILImage

from cat_server.domain.dto import (
    AnalysisResult,
    HaircutRecommendation,
    ImageData,
    NeuralNetworkRequest,
    NeuralNetworkResponse,
    ProcessingError,
    ProcessingException,
    ProcessingResult,
    ValidationResult,
)
from cat_server.infrastructure.repositories import (
    ICatsRepository,
    IHaircutsRepository,
    IRecommendationsRepository,
)
from cat_server.services.neural_service import NeuralService
from cat_server.services.user_session_service import UserSessionService

logger = logging.getLogger(__name__)


class NeuralNetworkClient:
    def __init__(self, base_url: str, timeout: int = 60):
        self.base_url = base_url
        self.timeout = timeout
        print(
            f"üîß NeuralNetworkClient –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å URL: {base_url}, timeout: {timeout}"
        )

    async def _process_with_local_neural(
        self, image_data: ImageData, neural_service: NeuralService
    ) -> NeuralNetworkResponse | None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ª–æ–∫–∞–ª—å–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é"""
        print("üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é...")

        neural_result = await neural_service.process_image(image_data.data)

        if not neural_result["success"]:
            raise ProcessingException(
                ProcessingError(
                    error_id="LOCAL_NEURAL_ERROR",
                    error_type="neural_local",
                    message=neural_result.get("error", "Local neural network error"),
                )
            )

        top_prediction = neural_result.get("top_prediction", {})

        # –°–æ–∑–¥–∞–µ–º AnalysisResult
        analysis_result = AnalysisResult(
            confidence=top_prediction.get("confidence", 0.0),
            analyzed_at=datetime.now(),
            predicted_class=top_prediction["class_name"],
        )

        processed_image = ImageData(
            file_name=f"processed_{image_data.file_name}",
            data=image_data.data,
            size=image_data.size,
            format=image_data.format,
            resolution=image_data.resolution,
            is_processed=True,
        )

        return NeuralNetworkResponse(
            analysis_result=analysis_result,
            processed_image=processed_image,
            processing_time_ms=0,
            processing_metadata={
                "model_type": "teachable_machine",
                "predictions": neural_result.get("predictions", []),
                "top_prediction": top_prediction,
            },
        )

    async def analyze_and_process_image(
        self, request: NeuralNetworkRequest
    ) -> NeuralNetworkResponse | None:
        async with aiohttp.ClientSession() as session:
            form_data = aiohttp.FormData()
            form_data.add_field(
                name="image",
                value=request.image.data,
                filename=f"{request.image.file_name}",
                content_type=f"image/{request.image.format.lower()}",
            )

            metadata = {
                "processed_at": request.processing_type,
                "image_metadata": {
                    "filename": request.image.file_name,
                    "format": request.image.format,
                    "size": request.image.size,
                    "resolution": request.image.resolution,
                },
            }
            form_data.add_field("metadata", json.dumps(metadata))
            try:
                print(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ POST-–∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ {self.base_url}")
                async with session.post(
                    f"{self.base_url}",
                    data=form_data,
                    timeout=aiohttp.ClientTimeout(total=self.timeout),
                ) as response:
                    print(f"üì• –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: —Å—Ç–∞—Ç—É—Å {response.status}")
                    if response.status == 200:
                        response_data = await response.json()
                        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {response_data}")
                        return self._parse_success_response(response_data)
                    else:
                        processing_error = await self._handle_http_error(response)
                        raise ProcessingException(processing_error)

            except asyncio.TimeoutError:
                logger.error("‚è∞ –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
                raise ProcessingException(
                    ProcessingError(
                        error_id="NEURAL_API_TIMEOUT",
                        error_type="neural_api",
                        message="–ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∞ –≤–æ–≤—Ä–µ–º—è",
                        suggestions=["–£–≤–µ–ª–∏—á—å—Ç–µ timeout", "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ"],
                    )
                )

            except aiohttp.ClientError as e:
                logger.exception("üîå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
                raise ProcessingException(
                    ProcessingError(
                        error_id="NEURAL_API_CONNECTION",
                        error_type="neural_api",
                        message="–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏",
                        details=str(e),
                        suggestions=[
                            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ",
                            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ URL API",
                        ],
                    )
                )

    @staticmethod
    def _parse_success_response(
        neural_data: Dict[str, Any],
    ) -> NeuralNetworkResponse | None:
        print("üîÑ –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
        analysis_data = neural_data.get("analysis_result", {})
        analysis_result = AnalysisResult(
            confidence=analysis_data.get("confidence", 0.0),
            analyzed_at=datetime.fromisoformat(
                analysis_data.get("analysis_timestamp", datetime.now().isoformat())
            ),
            predicted_class=analysis_data.get("predicted_class", ""),
        )

        image_data = (
            neural_data["processed_image"] if "processed_image" in neural_data else {}
        )

        if len(image_data) == 0:
            return None

        image_bytes = base64.b64decode(image_data["data"])
        processed_image = ImageData(
            file_name=image_data["filename"],
            data=image_bytes,
            size=len(image_bytes),
            format=image_data["format"],
            resolution=image_data["resolution"],
            is_processed=True,
        )

        result = NeuralNetworkResponse(
            analysis_result=analysis_result,
            processed_image=processed_image,
            processing_time_ms=neural_data.get("processing_time_ms", 0),
            processing_metadata=neural_data.get("processing_metadata", {}),
        )
        print("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω")
        return result

    @staticmethod
    async def _handle_http_error(response: aiohttp.ClientResponse) -> ProcessingError:
        error_text = await response.text()
        logger.warning(
            f"‚ö†Ô∏è –ù–µ–π—Ä–æ—Å–µ—Ç—å –≤–µ—Ä–Ω—É–ª–∞ –æ—à–∏–±–∫—É: —Å—Ç–∞—Ç—É—Å {response.status}, —Ç–µ–∫—Å—Ç: {error_text}"
        )

        error_mapping = {
            400: ("NEURAL_API_BAD_REQUEST", "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å"),
            401: ("NEURAL_API_UNAUTHORIZED", "–ù–µ–∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø"),
            403: ("NEURAL_API_FORBIDDEN", "–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω"),
            404: ("NEURAL_API_NOT_FOUND", "–†–µ—Å—É—Ä—Å –Ω–µ –Ω–∞–π–¥–µ–Ω"),
            429: ("NEURAL_API_RATE_LIMIT", "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤"),
            500: ("NEURAL_API_SERVER_ERROR", "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"),
            503: ("NEURAL_API_UNAVAILABLE", "–°–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
        }

        error_id, default_message = error_mapping.get(
            response.status, ("NEURAL_API_UNKNOWN", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
        )

        return ProcessingError(
            error_id=error_id,
            error_type="neural_api",
            message=f"{default_message} (—Å—Ç–∞—Ç—É—Å: {response.status})",
            details=error_text[:500],
            suggestions=NeuralNetworkClient._get_error_suggestions(response.status),
        )

    @staticmethod
    def _get_error_suggestions(status_code: int) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é –æ—à–∏–±–æ–∫"""
        suggestions = {
            400: [
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
                "–£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö",
            ],
            429: ["–£–º–µ–Ω—å—à–∏—Ç–µ —á–∞—Å—Ç–æ—Ç—É –∑–∞–ø—Ä–æ—Å–æ–≤", "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ"],
            500: ["–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ", "–°–≤—è–∂–∏—Ç–µ—Å—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ò–ò —Å–µ—Ä–≤–∏—Å–∞"],
            503: ["–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç"],
        }
        return suggestions.get(
            status_code, ["–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ", "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É"]
        )


class ImageProcessingService:
    def __init__(
        self,
        cats_repo: ICatsRepository,
        haircut_repo: IHaircutsRepository,
        recommendations_repo: IRecommendationsRepository,
        user_session_service: UserSessionService,
        neural_client: NeuralNetworkClient,
    ):
        self.cats_repo = cats_repo
        self.haircut_repo = haircut_repo
        self.recommendations_repo = recommendations_repo
        self.user_session_service = user_session_service
        self.neural_client = neural_client

    async def process_images(
        self,
        image_data: ImageData,
    ) -> ProcessingResult:
        start_time = datetime.now()
        try:
            nn_request = NeuralNetworkRequest(
                image=image_data,
                processing_type="analysis and enhancement",
            )
            print("üß† –û—Ç–ø—Ä–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—å...")
            nn_response = await self.neural_client.analyze_and_process_image(nn_request)

            if nn_response is None:
                processing_time_ms = int(
                    (datetime.now() - start_time).total_seconds() * 1000
                )
                return ProcessingResult(
                    analysis_result="nothing",
                    processing_time_ms=processing_time_ms,
                    status="error",
                    error=ProcessingError(
                        error_id="NEURAL_NETWORK_ERROR",
                        error_type="neural_network",
                        message="–û—à–∏–±–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏",
                        details="–ö–æ—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω",
                    ),
                )

            cat = await self.cats_repo.create()

            recommendation = await self.recommendations_repo.create(
                cat.id,  # pyright: ignore[reportArgumentType]
                nn_response.analysis_result.predicted_class,
                nn_response.analysis_result.confidence,
            )
            del recommendation

            processing_time_ms = int(
                (datetime.now() - start_time).total_seconds() * 1000
            )
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ: –≤—Ä–µ–º—è={processing_time_ms}ms")

            return ProcessingResult(
                cat_id=cat.id,  # pyright: ignore[reportArgumentType]
                analysis_result=nn_response.analysis_result,
                processing_time_ms=processing_time_ms,
                status="completed",
                error=None,
            )

        except ProcessingException as e:
            logger.warning(
                f"‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–æ–π (–æ–∂–∏–¥–∞–µ–º–æ–π): {e.error.message}"
            )
            processing_time_ms = int(
                (datetime.now() - start_time).total_seconds() * 1000
            )
            return ProcessingResult(
                processing_time_ms=processing_time_ms,
                status="error",
                error=e.error,
            )
        except Exception as e:
            logger.exception("üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            processing_time_ms = int(
                (datetime.now() - start_time).total_seconds() * 1000
            )
            return ProcessingResult(
                analysis_result="nothing",
                processing_time_ms=processing_time_ms,
                status="error",
                error=ProcessingError(
                    error_id="UNKNOWN_ERROR",
                    error_type="system",
                    message="–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞",
                    details=str(e),
                ),
            )

    async def validate_image(self, image_data: ImageData) -> ValidationResult:
        print("üîç –ù–∞—á–∞–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        errors = []

        if image_data.size > 10 * 1024 * 1024:  # 10MB
            errors.append(
                ProcessingError(
                    error_id="VALIDATION_SIZE",
                    error_type="validation",
                    message=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_data.file_name} –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10MB",
                    suggestions=["–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–º –¥–æ 10MB"],
                )
            )

        try:
            with PILImage.open(io.BytesIO(image_data.data)) as img:
                width, height = img.size
                if width < 640 or height < 480:
                    errors.append(
                        ProcessingError(
                            error_id="VALIDATION_RESOLUTION",
                            error_type="validation",
                            message=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_data.file_name} –∏–º–µ–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ",
                            details=f"–¢–µ–∫—É—â–µ–µ: {width}x{height}, –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ: 640x480",
                            suggestions=[
                                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ–º"
                            ],
                        )
                    )

                image_data.resolution = f"{width}x{height}"

        except Exception as e:
            errors.append(
                ProcessingError(
                    error_id="VALIDATION_FORMAT",
                    error_type="validation",
                    message=f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_data.file_name}",
                    details=str(e),
                    suggestions=["–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç JPEG –∏–ª–∏ PNG"],
                )
            )

        print(f"üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –æ—à–∏–±–æ–∫={len(errors)}")
        return ValidationResult(is_valid=len(errors) == 0, errors=errors)

    async def get_processing_result(self, cat_id: int) -> Dict[str, Any] | None:
        recommendation = await self.recommendations_repo.get_by_cat_id(cat_id)
        if recommendation is None:
            return None

        haircut = await self.haircut_repo.get_by_id(recommendation.haircut_id)
        if haircut is None:
            return None

        return {
            "cat_id": cat_id,
            "image": haircut.image_bytes,
            "recommendation": HaircutRecommendation(
                haircut_name=haircut.name,  # pyright: ignore[reportArgumentType]
                haircut_description=haircut.description,  # pyright: ignore[reportArgumentType]
            ),
        }
